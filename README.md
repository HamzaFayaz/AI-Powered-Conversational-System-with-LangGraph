# Agentic_Chatbot
<div align="center">

![LangGraph](https://img.shields.io/badge/LangGraph-FF6B6B?style=for-the-badge&logo=python&logoColor=white)
![React](https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB)
![LangSmith](https://img.shields.io/badge/LangSmith-00C4CC?style=for-the-badge&logo=python&logoColor=white)
![Groq](https://img.shields.io/badge/Groq-00C4CC?style=for-the-badge&logo=python&logoColor=white)

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg?style=for-the-badge)](https://www.python.org/downloads/)
[![Node.js 18+](https://img.shields.io/badge/node.js-18+-green.svg?style=for-the-badge)](https://nodejs.org/)

</div>

---

## ğŸ“‹ **About This Project**

An advanced **AI-powered conversational system** built with modular architecture for scalability, maintainability, and clarity. The project leverages **LLMs orchestrated through LangGraph** for structured reasoning, while maintaining a professional ingestion workflow to handle document uploads and populate a vector database for accurate retrieval.  

### **What Makes It Special:**
- ğŸ§  **Agent-Centric Design**: Agents are fully separated from prompts, nodes, and graph logic for clean reasoning flow.  
- ğŸ“‚ **Structured Ingestion**: Dedicated ingestion pipeline for loading, chunking, and embedding documents into the vector database.  
- ğŸ” **Powerful Retrieval**: Optimized vector search ensures precise context recall for user queries.  
- ğŸª„ **Modular Workflow**: Clear split between core logic (agents, nodes, graph) and shared helpers (utils, config) for easy scaling.  
- ğŸ“Š **Transparent Orchestration**: LangGraph-based graph definition provides visibility and control over multi-step reasoning.  
- âš¡ **Seamless Integration**: Built-in support for FAISS/Pinecone and other vector DBs for flexible deployment.  
- ğŸ³ **Unified Dockerization**: Frontend (React) and Backend (FastAPI) fully containerized and deployed together.  
- ğŸ”„ **Automated CI/CD Pipeline**: Continuous integration and delivery for seamless testing, building, and deployment.  
- â˜ï¸ **Cloud Ready**: Supports deployment on **AWS EC2** with container images stored in **Amazon ECR** for production scalability.  
- ğŸ’» **Local Friendly**: Runs smoothly on local machines or Codespaces with Docker Compose if AWS is not required.  

---

## ğŸ“¸ **Demo & Screenshots**

Here are some snapshots that highlight the system in action:  

### ğŸ’¬ Chatbot Demo  
Showcasing real-time interaction with the AI-powered conversational system.  
<img width="650" height="961" alt="chatbot_1" src="https://github.com/user-attachments/assets/8e06bc06-c1ff-4440-88b0-cfd1d6e33434" />
<img width="650" height="713" alt="chatbot_2" src="https://github.com/user-attachments/assets/1866612a-9ccb-4fcf-9e97-3473d6c67832" />



---

### â˜ï¸ AWS EC2 Deployment  
CI/CD pipeline success message from the **EC2 instance terminal**.  

<img width="1527" height="696" alt="Runner aws" src="https://github.com/user-attachments/assets/00d84f1c-ef9d-405a-b451-75bcd6ac779b" />

---

### ğŸ”„ GitHub Actions Workflow  
Successful **workflow run** demonstrating automated CI/CD.  

<img width="1746" height="712" alt="cicd running" src="https://github.com/user-attachments/assets/fd462323-ecc1-4eab-ae38-054742a84a05" />


---

## ğŸš€ Key Features

### Core Functionality
- ğŸ§  **AI-Powered Agents**: Modular agents designed for reasoning, tool use, and clean separation from prompts and graph logic.  
- ğŸ“‚ **Document Ingestion & Management**: Upload, split, and embed documents into FAISS/Pinecone vector databases.  
- ğŸ” **RAG (Retrieval-Augmented Generation)**: Context-aware query responses using vector embeddings for precise retrieval.  
- ğŸª„ **LangGraph Orchestration**: Multi-stage conversational workflow built with LangGraph for structured reasoning.  
- âš¡ **Real-time Query Handling**: Asynchronous FastAPI endpoints for fast, scalable request processing.  
- ğŸ“Š **Transparent Execution**: Workflow steps traceable through LangGraphâ€™s state graph definition.  
- ğŸ”Œ **Seamless Integration**: Built-in support for FAISS and Pinecone for flexible storage/retrieval.  

### Frontend Features
- ğŸ¨ **Modern UI**: Built with React, Tailwind CSS, and Framer Motion for a sleek, interactive design.  
- ğŸ“± **Responsive Design**: Mobile-friendly interface with adaptive layouts.  
- ğŸ“‚ **File Upload**: Drag-and-drop document upload with progress indicators.  
- ğŸ’¬ **Chat Interface**: Conversational chatbot UI with context-aware responses.  
- ğŸ”„ **Live Updates**: Real-time chat flow and retrieval tracking.  
- ğŸ§© **API Integration**: Direct connection to FastAPI backend endpoints.  

### Backend Features
- âš¡ **FastAPI Backend**: High-performance Python backend serving as the core API layer.  
- ğŸª„ **LangGraph Workflow Engine**: Node-based orchestration of agent workflows.  
- ğŸ“‚ **Vector Database**: FAISS/Pinecone support for document storage and retrieval.  
- ğŸ§  **Agents & Tools**: Clear separation of agents, prompts, nodes, and ingestion pipelines.  
- ğŸ”„ **Asynchronous Processing**: Handles multiple concurrent requests with async FastAPI.  
- ğŸ“œ **API Documentation**: Auto-generated OpenAPI docs available at `http://localhost:8000/docs`.  
- ğŸ³ **Docker Support**: Ready for containerized deployment and scaling.  

---
## ğŸ—ï¸ **System Architecture**

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend       â”‚    â”‚     AI Services       â”‚
â”‚   (React)       â”‚â—„â”€â”€â–ºâ”‚ (FastAPI +      â”‚â—„â”€â”€â–ºâ”‚   (LangGraph + LLMs)  â”‚
â”‚                 â”‚    â”‚   LangGraph)    â”‚    â”‚                       â”‚
â”‚ â€¢ Chatbot UI    â”‚    â”‚ â€¢ API Gateway   â”‚    â”‚ â€¢ Agents & Graph Flow â”‚
â”‚ â€¢ File Upload   â”‚    â”‚ â€¢ Ingestion     â”‚    â”‚ â€¢ Retrieval + RAG     â”‚
â”‚ â€¢ Live Updates  â”‚    â”‚ â€¢ Vector Store  â”‚    â”‚ â€¢ Document Embedding  â”‚
â”‚ â€¢ Reports       â”‚    â”‚ â€¢ CI/CD Hooks   â”‚    â”‚ â€¢ AWS EC2 + ECR       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

```

---

## ğŸ“ **Project Structure**

The project follows a clean and modular structure for clarity and scalability.  

```text
chatbot-project/
â”œâ”€â”€ backend/                     # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ agents/              # AI agents
â”‚   â”‚   â”œâ”€â”€ api/                 # API routes
â”‚   â”‚   â”œâ”€â”€ core/                # Core logic (entrypoints)
â”‚   â”‚   â”œâ”€â”€ graph/               # LangGraph workflows
â”‚   â”‚   â”œâ”€â”€ ingestion/           # Document ingestion pipeline
â”‚   â”‚   â”œâ”€â”€ models/              # ML/LLM models
â”‚   â”‚   â”œâ”€â”€ prompts/             # LLM prompts
â”‚   â”‚   â”œâ”€â”€ tools/               # Helper tools
â”‚   â”‚   â”œâ”€â”€ __init__.py          # Package init
â”‚   â”‚   â””â”€â”€ main.py              # FastAPI app entrypoint
â”‚   â”œâ”€â”€ run.py                   # Run script
â”‚   â”œâ”€â”€ requirements.txt         # Python dependencies
â”‚   â”œâ”€â”€ .env                     # Environment variables
â”‚   â””â”€â”€ Dockerfile               # Backend Docker configuration
â”‚
â”œâ”€â”€ frontend/                    # React frontend
â”‚   â”œâ”€â”€ public/                  # Static assets
â”‚   â”œâ”€â”€ src/                     # Frontend source code
â”‚   â”‚   â”œâ”€â”€ components/          # React components
â”‚   â”‚   â”œâ”€â”€ services/            # API services
â”‚   â”‚   â””â”€â”€ utils/               # Frontend utilities
â”‚   â”œâ”€â”€ package.json             # Node.js dependencies
â”‚   â”œâ”€â”€ package-lock.json        # Dependency lock file
â”‚   â””â”€â”€ tailwind.config.js       # Tailwind CSS config
â”‚
â”œâ”€â”€ docker-compose.yml           # Compose for fullstack deployment
â”œâ”€â”€ .dockerignore                # Files ignored by Docker
â””â”€â”€ README.md                    # Project documentation
```

## ğŸ› ï¸ Technology Stack  

### Backend  
- **FastAPI**: Modern Python web framework for building APIs  
- **Uvicorn**: Lightning-fast ASGI server for running FastAPI  
- **Docker**: Containerization for consistent deployments  
- **AWS EC2**: Hosting the backend on a scalable cloud VM  
- **AWS ECR** *(optional)*: Private container registry for storing Docker images  

### Frontend  
- **React 18**: UI framework for building responsive frontend  
- **Tailwind CSS**: Utility-first CSS framework for styling  
- **Framer Motion**: Animation library for smooth UI interactions  
- **React Hook Form**: Form handling and validation  
- **React Dropzone**: File upload functionality  
- **Headless UI**: Accessible, unstyled components  

### AI/ML  
- **Sentence Transformers**: Text embeddings for semantic similarity  
- **FAISS**: Vector similarity search for efficient retrieval  
- **LangChain**: LLM orchestration and RAG pipeline management  

### DevOps / CI/CD  
- **GitHub Actions**: Automating CI/CD workflows  
- **Docker**: Containerized builds for portability  
- **AWS EC2**: Deployment target for CI/CD pipeline  
---

## ğŸš€ Quick Start

Get the project running locally in just a few steps:  

```bash
# 1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/your-repo-name.git
cd your-repo-name

# 2ï¸âƒ£ Backend Setup (FastAPI)
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows

pip install -r requirements.txt

# Run the backend server
python run.py
# ğŸ‘‰ Backend available at http://127.0.0.1:8000

# 3ï¸âƒ£ Frontend Setup (React)
cd frontend
npm install
npm start
# ğŸ‘‰ Frontend available at http://localhost:3000

# 4ï¸âƒ£ Run with Docker (Optional)
# From the project root
docker build -t agentic-chatbot:latest .
docker run -d -p 8000:8000 --env-file backend/.env agentic-chatbot:latest

# 5ï¸âƒ£ Deploy to AWS EC2 (Optional)
# Copy files to EC2 instance
scp -r . ubuntu@your-ec2-ip:/home/ubuntu/agentic-chatbot

# SSH into EC2
ssh ubuntu@your-ec2-ip

# Inside EC2 instance
cd agentic-chatbot
docker build -t agentic-chatbot:latest .
docker run -d -p 8000:8000 --env-file backend/.env agentic-chatbot:latest
```

